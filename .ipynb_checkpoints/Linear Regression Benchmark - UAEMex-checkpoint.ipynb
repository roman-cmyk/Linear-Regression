{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Linear Regression Benchmark</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Jupyter Notebook contains a Benchmark of the different approches for solving a Liner Regression Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In statistics, linear regression is a linear approach to modelling the relationship between a dependent variable and one or more independent variables. Let $X$ be the independent variable and $Y$ be the dependent variable. We will define a linear relationship between these two variables as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Equation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Y = mX + c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the equation for a line, where $m$ is the slope of the line and $c$ is the $y$ intercept. For this exercise we will use this equation to train our model with a given dataset and predict the value of $Y$ for any given value of $X$. Our challenge will be to determine the value of $m$ and $c$, such that the line corresponding to those values is the best fitting line or gives the minimum error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lost Function\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss is the error in our predicted value of $m$ and $c$. Our goal is to minimize this error to obtain the most accurate value of $m$ and $c$.\n",
    "We will use the $Mean Squared Error Function$ to calculate the loss. There are three steps in this function:\n",
    "\n",
    "##### 1.- Find the difference between the actual $y$ and predicted $y$ value($y = mx + c$), for a given $x$.\n",
    "##### 2.- Square this difference.\n",
    "##### 3.- Find the mean of the squares for every value in $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error Equation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$MSE = \\frac{1}{m} \\sum_{i=1}^m (y_i - ȳᵢ)^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here yᵢ is the actual value and ȳᵢ is the predicted value. Lets substitute the value of ȳᵢ:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$MSE = \\frac{1}{m} \\sum_{i=1}^m (y_i - (m*x_i + c)^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we Square the Error and find the Mean. Hence the name Mean Squared Error. Now that we have defined the Loss Function, lets get into the interesting part — minimizing it and finding $m$ and $c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
